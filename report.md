# 机器学习概论 实验二 实验报告

* 班级：计 76
* 姓名：王聿中
* 学号：2017011382

## 1. 简介

本实验致力于使用集成学习算法解决商品评分预测的问题。

## 2. 实验方法

### 2.1. 问题描述

商品评分预测问题，即对于给定的商品评价文本，预测评价者对该商品的评分具体为多少。

本实验中，数据来源为亚马逊平台的若干购买评价，具体评分为 $1\sim 5$ 之间的整数。特别地，预测模型可以作出非整数的预测。

### 2.2. 算法

分别使用集成学习算法 Bagging 及 Adaboost.M1，与传统机器学习模型 SVM 及决策树两两结合，考察它们在商品评分预测问题上的不同表现。

#### Bagging

Bagging 算法的基本假设为: 小量数据训练的多个分类器投票比全数据训练的单个分类器效果更好。

Bagging 算法包含两个参数 $m$ 与 $t$，其算法流程如下：

* **输入与准备** 选取一种不稳定的分类器 X，给定一个 $n$ 个样例的训练集 $D$。

* **训练** 对于 $i=1,\cdots t$：随机放回地取样，取 m 个样例作为子集 $D_i$，作为新的训练集。训练得到一个分类器 $X_i$。

* **预测** 对于输入的样例，使用分类器 $X_1, \cdots, X_t$ 各得到一个结果。如果任务类型为分类，则按照投票得出结果；如果是回归问题，则取均值作为结果。

#### Adaboost.M1

Adaboost.M1 算法的基本思想为：对往次训练错误的样本，在后续训练中强化它们的重要性。并由不同分类器在训练中的错误率决定它们各自在预测时的权重。

Bagging 算法包含一个参数 $t$，其算法流程如下：

* **输入与准备** 选取分类器 X，给定一个 $n$ 个样例的训练集 $D$。初始化各样本 $j$ 的权重 $w_j=\frac{1}{n}$。

* **训练** 对于 $i=1,\cdots t$：

    * 带权重 $w_j$ 地使用训练集数据训练模型 $X_i$，并计算其在训练集上预测的错误率 $\epsilon_i$，错误率的具体定义为错误样本的权重总和。
    
    * 如果 $\epsilon > 0.5$，则立刻抛弃当前的分类器，令 $t=i-1$，直接停止训练。

    * 令 $\beta_i = \frac{\epsilon_i}{1-\epsilon_i}$。对于所有**正确样例** $j$，将其权重 $w_j$ 置为 $\beta_i w_j$；对于错误样例，保持其现有权重不做任何操作。

    * 将所有样例的权重归一化，用于下一轮训练。

* **预测** 对于输入的样例，使用分类器 $X_1, \cdots, X_t$ 各得到一个结果。对于每个分类器 $X_i$，令其权重为 $\log \frac{1}{\beta_i}$。如果任务类型为分类，则按照权重加权投票得出结果；如果是回归问题，则按权重取加权平均作为结果。

## 3. 实验

### 3.1. 实验设定

我们使用 TF-IDF 作为编码器对文本进行特征提取并编码。

对于数据集，我们随机选出其中 $10\%$ 作为验证集，剩余部分作训练集。我们将会在后面的部分中汇报各实验在验证集上的结果。由于实验项数较多，我们不会将所有实验提交到 kaggle 平台上进行测试，因此我们将选取其中个别实验提交 kaggle 平台，并观察这些结果在验证集和测试集上表现的差异。实验结果将表明此二者间差异较小，从而证明验证集测试结果可以较大程度上地反映测试集测试结果。

我们将分别使用 SVM、决策树作为**分类**或**回归**模型进行实验。

对于 Adaboost.M1 算法，我们有如下设定和处理：

* 对于分类任务：综合考虑训练效果和计算资源，我们将对**训练数据**进行采样，在保留尽可能多数据的情况下，使各标签的样本数相等。

* 对于 SVM 模型：考虑到其效率，我们将削减训练数据，具体地，我们在（可能的）采样后，保留其中的 $3000$ 条作为最终训练数据（若不足则全部保留）。

* 对于回归任务：我们定义算法训练流程中**正确样例**为预测结果四舍五入后与标签一致的样例，错误样例即为非正确样例。

我们将使用 RMSE 作为指标对模型预测效果进行评价。设测试集样本数为 $n$，对于第 $i$ 个样本，其标签为 $y_i$ 且预测结果为 $p_i$。则 RMSE 定义如下：

$$
\text{RMSE}=\sqrt{\frac{\sum_{i=1}^{n} \left(p_i-y_i\right)^2}{n}}
$$

### 3.2. 不同算法、不同参数的对比实验

我们选取了不同的参数分别进行了八种组合的实验。实验结果如下：

<table>
  <tr><td rowspan="2">集成算法</td><td colspan="2" rowspan="2">参数</td><td colspan="2">SVM</td><td colspan="2">决策树</td></tr>
  <tr><td>分类</td><td>回归</td><td>分类</td><td>回归</td></tr>
  <tr><td rowspan="6">Baging</td><td rowspan="3">m=1000</td><td>t=10</td>
    <td>1.2779</td><td>0.9477</td><td>1.2800</td><td>1.0633</td>
  </tr>
  <tr><td>t=25</td>
    <td>1.2809</td><td>0.9434</td><td>1.2887</td><td>1.0312</td>
  </tr>
  <tr><td>t=50</td>
    <td>1.2790</td><td>0.9418</td><td>1.3114</td><td>1.0186</td>
  </tr>
  <tr><td rowspan="3">m=3000</td><td>t=10</td>
    <td>1.1960</td><td>0.9065</td><td>1.2732</td><td>1.0292</td>
  </tr>
  <tr><td>t=25</td>
    <td>1.1981</td><td>0.8951</td><td>1.2461</td><td>1.0074</td>
  </tr>
  <tr><td>t=50</td>
    <td>1.1956</td><td>0.8912</td><td>1.2591</td><td>1.0007</td>
  </tr>
  <tr><td rowspan="6">Adaboost.M1</td><td colspan="2">t=5</td>
    <td>1.3760</td><td>1.0572</td><td>1.4536</td><td>1.0220</td>
  </tr>
  <tr><td colspan="2">t=10</td>
    <td>1.3763</td><td>1.0734</td><td>1.4033</td><td>1.0095</td>
  </tr>
  <tr><td colspan="2">t=15</td>
    <td>1.3881</td><td>1.0810</td><td>1.3129</td><td>0.9952</td>
  </tr>
  <tr><td colspan="2">t=20</td>
    <td>1.5241</td><td>1.0780</td><td>1.3419</td><td>0.9934</td>
  </tr>
  <tr><td colspan="2">t=25</td>
    <td>1.3958</td><td>1.0569</td><td>1.3321</td><td>0.9960</td>
  </tr>
  <tr><td colspan="2">t=30</td>
    <td>1.6531</td><td>1.0737</td><td>1.3296</td><td>0.9900</td>
  </tr>
</table>

从以上结果，我们发现了一些初步的结论，并加以论述如下：

* **在使用 SVM 作为分类器时，Bagging 算法普遍优于 Adaboost.M1 算法。**这一现象可解释为，SVM 本身是一个强分类器，容易产生对训练数据的过拟合。实际实验中，我们可以发现，SVM 几乎可以对测试集达到 100% 的准确率。而 Adaboost.M1 算法需要利用错误样本来训练新的分类器，依赖了分类器的弱分类器的特点，因此其对 SVM 并不奏效。
* **在使用决策树作为分类器时，Bagging 算法的预测表现与 Adaboost.M1 算法相当。**这一结论与我们在上面提到的 SVM 的结论不同。我们认为这是由于决策树是一个弱分类器，而如上面所述地，Adaboost.M1 能够很好地利用其弱性和不稳定性，使得错误样本被放大时分类器可以有不同的表现，从而平衡分类效果。因此，Adaboost.M1 加持下的决策树也能够与 Bagging 算法取得一致的效果。
* **在使用相同模型、参数、集成学习算法时，回归模型的表现往往优于分类模型。**我们认为，这是由于回归模型能更好地对数据作定量的拟合。电商平台上的商品评分事实上是一个标量数值，而像分类模型那样将它们看作非五个独立的标签。评分数值之间存在偏序关系，而回归模型更重视这一关系，我们认为这即是回归模型在这个任务上优于分类模型的原因。
* **对于 Bagging 算法，更大的参数 $t,m$ 都会带来更高的预测准确性，且 $m$ 的增长对模型效果的提升更为明显。**前半部分的结论（$t,m$ 增长提升预测准确率）是符合直觉的，更多的模型会提升整体的稳定性和准确率，而更多的数据一般也能够使得预测结果更准确。后半部分（$m$ 增长更能提升预测表现）我们认为其原因在于，Bagging 算法中 $t$ 带来的更多模型，更多地是帮助整体预测进行容错、提升稳定性，以此达到提升预测表现的目的，而这样的做法带来的增益并没有增大数据量来得大。
* **对于 Adaboost.M1 算法：若配合决策树使用，则更大的参数 $t$ 往往能带来更高的预测准确性；而若配合 SVM 使用，则结果略有波动。**这其中的原因在上面也有所涉及。一方面，Adaboost.M1 能够很好地利用决策树的弱性，弥补其这方面的缺陷，而模型越多则会有更多错误样本被重视，从而表现出更高的准确率。另一方面，SVM 作为强分类器，本身并不适合搭配 Adaboost.M1 来使用，因此其糟糕的效果和波动是可以解释的。
* **总体来看，SVM 在这个任务上表现得比决策树更好。**这一现象包含了多方面的因素，我们无法通过现有的结论来论证这一点。作为替代，我们提出针对这一结论的如下猜想：
  * 决策树的训练参数、训练数据处理等训练细节未做到最优。
  * SVM 比决策树更适合这一任务。这可能是由于这是一个五分类任务，且其难度主观来看并不低。

### 3.3. 验证集和测试集结果的对比

如 [3.1.](#3.1. 实验设定) 中所述，我们选取了一些实验，检查它们在验证集、测试集上表现的差异。参数上我们都选取了上一章节中对应算法的最大参数，即对于 Bagging 取 $t=50, m=3000$，对于 Adaboost.M1 取 $t=30$。

<table>
  <tr><td>集成算法</td><td>分类模型</td><td>任务类型</td><td>验证集 RMSE</td><td>测试集 RMSE</td></tr>
  <tr><td>Adaboost.M1</td><td>SVM</td><td>分类</td><td>1.6531</td><td>1.65176</td></tr>
  <tr><td>Adaboost.M1</td><td>SVM</td><td>回归</td><td>1.0737</td><td>1.05572</td></tr>
  <tr><td>Adaboost.M1</td><td>决策树</td><td>分类</td><td>1.3296</td><td>1.35449
</td></tr>
  <tr><td>Adaboost.M1</td><td>决策树</td><td>回归</td><td>0.9900</td><td>0.98832</td></tr>
  <tr><td>Bagging</td><td>SVM</td><td>分类</td><td>1.1956</td><td>1.18532</td></tr>
</table>

由于平台提交次数限制，我们无法测试更多的实验结果。但从上面的结果可以看出验证集和测试集的结果差异较小。这说明了，验证集的划分是足够随机的，训练过程不存在数据泄露，且验证集的测试结果足以代表、反映对应算法在测试集上的结果。

### 3.4. 追求最好的效果

从 [3.2.](#3.2. 不同算法、不同参数的对比实验) 中，由于 Bagging 与回归 SVM 的组合可以获得最好的效果。因此，我们尝试在此组合下，研究如何获得最好的效果。

上一章节的实验结果已经解释了对 Bagging 算法参数的初步结论：

* 更大的参数 $t$ 会带来更高的预测准确性，但并不明显。

* 更大的参数 $m$ 会带来更搞的预测准确性，且相较 $t$ 的影响更为明显。

结合考虑到计算资源有限，因此我们暂且忽略 $t$ 对结果的影响，试图通过增大 $m$ 的方式来获得更优的效果。然而事与愿违，我们发现，当我们设定 $m$ 为 $2\times 10^4$ 时，实验结果为 $\text{RMSE}=0.996$，与我们的初步结论矛盾。因此，我们展开了实验，考察固定 $t=50$、分类器为 SVM，任务类型为回归时，$m$ 的变化与预测准确性的关系。实验结果如下：

<table>
  <tr><td>m</td><td>5000</td><td>6000</td><td>7000</td><td>8000</td><td>9000</td><td>10000</td></tr>
  <tr><td>RMSE</td><td>0.8763</td><td>0.8739</td><td>0.8730</td><td>0.8728</td><td>0.8739</td><td>0.8770</td></tr>
</table>

实验结果大致表明，$m$ 的增长并不总是导致预测结果变优。预测结果关于 $m$ 大致呈单峰的趋势。我们认为，这可能是由于过多的数据，会导致强分类器 SVM 出现过拟合现象所导致。

综上，我们最终选择了 $m=8000$ 的版本作为我们的最终提交。

### 3.5. 最终成绩和排名

最终版本的白盒成绩为 $\text{RMSE}=0.xxxx$，截止 2020 年 5 月 10 日 13 时排名第 1。

注：由于本报告于 10 日 13 时许直接提交，故对此排名不作后续更新，敬请谅解。

### 3.6. 讨论：Bagging 和 AdaBoost 的区别

* Bagging 主要改善分类器的不稳定性。其方法为随机抽样，并保持各分类器权重相同，使得不同小量训练能够造成不同的分类结果，从而对预测起到平衡的作用。 

* Adaboost.M1 依赖的是分类器的弱性和不稳定性。其主要思想是不断强化错误案例，并使得错误案例被放大时分类器能够有不同的表现，从而平衡预测效果。

## 4. 总结

本次实验中，我们使用了两种集成学习算法尝试解决了商品评分预测的任务。实验结果显示，在这个任务上：

1. 使用 SVM 作为分类器时：Bagging 算法比 Adaboost.M1 算法效果更好。导致这一现象的成因是 SVM 是一个强分类器，容易产生对训练数据的过拟合，因此 Adaboost.M1 算法对其并不奏效。
2. 使用决策树作为分类器时：Bagging 算法与 Adaboost.M1 算法效果大致相当。我们认为这一结论与 SVM 不同的原因是由于决策树是一个弱分类器，Adaboost.M1 能够很好地利用其作为弱分类器的特点，使得错误样本被放大时分类器可以有不同的表现，从而平衡分类效果。
3. 回归模型的表现往往优于分类模型。我们认为这是由于回归模型能更好地对数据作定量的拟合，而非像分类问题那样将 $1\sim 5$ 颗星作为五个 nominal 的标签。
4. 总体来讲，Bagging+SVM+回归的方法表现最好。其中的原因可能是多样的。
5. 数据量过大（即 Bagging 算法的参数 $m$ 过大）可能会导致 SVM 对训练数据的过拟合。

## 5. 致谢

感谢陈果、顾掀宇两位同学在本次实验中对我的帮助。

感谢助教的耐心批阅。

感谢老师的精彩授课。

## 6. 附录

### 关于代码实现的一些说明

本项目基于我个人开发的一个机器学习训练框架 [sklearn_worker](https://github.com/wangyurzee7/sklearn_worker)，该项目的部分模式、思路、框架参考了本人实验室学长所开发的一个深度学习训练框架 [pytorch-worker](https://github.com/haoxizhong/pytorch-worker)。

本项目的 Git Repo 为：[EnsembleLearning4RatingPrediction](https://github.com/wangyurzee7/EnsembleLearning4RatingPrediction)

###Guide 中要求在本文中的对应

* Your experimental design. [2. 实验方法](#2. 实验方法)
* The experimental results: the results of 4 required combinations. [3.2. 不同算法、不同参数的对比实验](#3.2. 不同算法、不同参数的对比实验)
* Performance of different methods on Kaggle's evaluation set and the rank on the leaderboard [3.3. 验证集和测试集结果的对比](#3.3. 验证集和测试集结果的对比)、[3.4. 追求最好的效果](#3.4. 追求最好的效果)、[3.5. 最终成绩和排名](#3.5. 最终成绩和排名)
* Your analysis and discussion. For example: 
  * Why do the algorithms mentioned above perform differently or similarly on the dataset? [3.2. 不同算法、不同参数的对比实验](#3.2. 不同算法、不同参数的对比实验)、[4. 总结](#4. 总结)
  * What is the difference between Bagging and AdaBoost? [2. 实验方法](#2. 实验方法)、[3.6. 讨论：Bagging 和 AdaBoost 的区别](3.6. 讨论：Bagging 和 AdaBoost 的区别)
  * Which combination is the best one and why? [3.2. 不同算法、不同参数的对比实验](#3.2. 不同算法、不同参数的对比实验)、[3.4. 追求最好的效果](#3.4. 追求最好的效果)